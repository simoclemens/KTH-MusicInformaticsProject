{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DT2470 Music Informatics project\n",
    "Alice Anselmi | Simone Clemente | Stefano Scolari\n",
    "### Task and purpose of the project\n",
    "The goal of this project is to create an automatic mixer based on key and beat detection. <br>\n",
    "The core idea is to start from a series of segments and mix them in the best possible way considering both BPM and key similarity.\n",
    "### Dataset and methods\n",
    "We worked with annotated datasets in order to have ground truth for beat and key. (For instance: https://zenodo.org/record/3967852). The dataset is composed by a series of tracks in *wav* format which have been annotated with the key and the BPM, as well as other information related to the track. <br>\n",
    "The data was filtered to select only the tracks that were classified as *techno* and *house* music.\n",
    "### Musical lineup creation\n",
    "Once we have computed the estimated key and bpm for each track it is time to order them with the purpose of creating an actual lineup. <br>The basic idea behind this process is to find tracks which are similar to each other and put them one close in order to have a seamless passage.\n",
    "In order to define the similarity we could consider a 2D-dimensional plane with key and bpm as axis: our target is to find the closest neighbors of our current track. Since summing together the distances in terms of key and bpm is not simple, we decided to use an approach derived from the classical mixing theory.\n",
    "##### Key similarity\n",
    "In order to find the similarity between keys we decided to apply the Camelot Wheel rule: said wheel is composed by two circles, the outer representing major keys and the inner minor keys. It is often used for mixing since it indicates the keys which works well together: as a matter of fact, each key sounds well with the two neighbors in its circle and with the correspondent element from the other circle. In this way, once we select a track, we can divide the 2D plane in horizontal segments and select only those which have a key admissible from the Camelot rule.\n",
    "##### BPM similarity\n",
    "Since we used the key to segment the plane now the nearest neighbors search can be done in 1D using simply the BPM difference between two tracks as similarity measure. Usually DJs tend to increase the BPM of the mix with time: to mimic this behaviour we inserted an additional constraint related to the tempo. As a matter of fact we only consider the tracks with BPM higher or equal to the current one. In this way, the next piece will be the track with the most similar BPM to the actual one only considering those from the selected group of keys and having a faster tempo.\n",
    "\n",
    "We are working with two features so the first idea was to apply a simple 2-dimensional nearest neighbor search to find the closest [TODO]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Input directory selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# insert the tracks you want to mix into the input folder\n",
    "input_path = \"input_folder\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "##### Track features extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRACK: input_folder/Bitter Sweet (mp3cut.net).wav -> BPM:129.19921875 KEY:A major\n",
      "TRACK: input_folder/Inside Out (mp3cut.net).wav -> BPM:129.19921875 KEY:G minor\n",
      "TRACK: input_folder/MOI004 A (mp3cut.net).wav -> BPM:83.35433467741936 KEY:A minor\n"
     ]
    }
   ],
   "source": [
    "from tracks import TrackFeatures\n",
    "track_list = os.listdir(input_path)\n",
    "\n",
    "# Key extraction modes: \"determ\" for deterministic, \"nn\" for neural network\n",
    "key_mode = \"determ\"\n",
    "# Bpm extraction modes: \"dynamic\" for dynamic, \"nn\" for neural network\n",
    "bpm_mode = \"dynamic\"\n",
    "\n",
    "for track_file in track_list:\n",
    "    file_path = str(input_path + \"/\" + track_file)\n",
    "    track = TrackFeatures(file_path, key_mode, bpm_mode)\n",
    "    track.extractFeatures()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "##### Musical lineup creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-09T17:21:42.940834900Z",
     "start_time": "2023-10-09T17:21:42.904139500Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'str' object has no attribute 'setSelected'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_27392\\200308320.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mnn_procedure\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mNNMixing\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mtrack_selection\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mNNMixing\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrack_list\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtrack_list\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mnumber_of_tracks\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mtrack_lineup\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrack_selection\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcreateMix\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mc:\\Users\\alice\\Desktop\\KTH-MusicInformaticsProject\\nn_procedure.py\u001b[0m in \u001b[0;36mcreateMix\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     31\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     32\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnumber_of_tracks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 33\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrack_list\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcurrent_idx\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msetSelected\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     34\u001b[0m             \u001b[0mcurrent_idx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnnSearch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcurrent_idx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     35\u001b[0m             \u001b[0mmix\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcurrent_idx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'str' object has no attribute 'setSelected'"
     ]
    }
   ],
   "source": [
    "from nn_procedure import NNMixing\n",
    "track_selection = NNMixing(track_list=track_list,number_of_tracks=5)\n",
    "track_lineup = track_selection.createMix()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "##### Mix creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from mixer import Mixer\n",
    "mixer = Mixer(track_lineup)\n",
    "mixer.createMix()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Accuracy of key and bpm estimation\n",
    "In order to evaluate the accuracy of the key and bpm estimation we decided to use the *accuracy* and *mean absolute error* metrics. <br>\n",
    "\n",
    "[TODO add plots/values]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
